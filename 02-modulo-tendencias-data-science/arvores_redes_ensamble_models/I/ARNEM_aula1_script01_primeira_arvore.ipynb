{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "Árvores\n",
    "Ensemble\n",
    "Machine Learning\n",
    "Redes Neurais\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias no arquivo 00\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para separar treino e teste\n",
    "# Métricas de avaliação do modelo programadas no scikit\n",
    "from sklearn.metrics import accuracy_score, classification_report, \\\n",
    "    confusion_matrix, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe de árvore e funções auxiliares\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  Funções Auxiliares\n",
    "\n",
    "from funcoes_ajuda import descritiva, relatorio_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  Carregar os dados\n",
    "titanic = sns.load_dataset('titanic')\n",
    "print(titanic.head())\n",
    "print(titanic.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  Análise descritiva básica\n",
    "\n",
    "for variavel in titanic.columns:\n",
    "    print(f'\\n\\nAnálise univariada de {variavel}:')\n",
    "    print(titanic[variavel].describe())\n",
    "\n",
    "    \n",
    "for variavel in ['pclass', 'sex', 'sibsp', 'parch', 'embarked', 'class', 'who', \n",
    "                 'adult_male', 'deck', 'embark_town', 'alive', 'alone']:\n",
    "    print(f'\\n\\nFrequencias da variável: {variavel}')\n",
    "    print(titanic[variavel].value_counts(dropna=False).sort_index())\n",
    "    \n",
    "\n",
    "descritiva(titanic, \"sex\")\n",
    "descritiva(titanic, \"class\")\n",
    "descritiva(titanic, \"age\", max_classes=10)\n",
    "descritiva(titanic, \"fare\", max_classes=5)\n",
    "descritiva(titanic,\"embarked\")\n",
    "descritiva(titanic,\"sibsp\")\n",
    "descritiva(titanic,\"parch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Avaliar dados faltantes\n",
    "\n",
    "# A função tem basicamenteum compilado desses comandos:\n",
    "# titanic.isna().sum()\n",
    "# titanic.isna().mean().apply(lambda x: f\"{x:.1%}\".)\n",
    "relatorio_missing(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Tratar variável age\n",
    "\n",
    "titanic['age'] = titanic.age.fillna(titanic.age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Remover variáveis redundantes\n",
    "titanic.drop(columns=['class', 'who', 'adult_male', 'deck', 'embark_town', \n",
    "                      'alive', 'alone'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Verificar variáveis string\n",
    "\n",
    "metadados = titanic.dtypes\n",
    "\n",
    "print('\\nVariávels string:')\n",
    "print(metadados[metadados == 'object'])\n",
    "\n",
    "metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Transformar variáveis string em dummies\n",
    "\n",
    "# No pandas, um método prático de fazer isto é com o get_dummies\n",
    "titanic_dummies = pd.get_dummies(titanic, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conferir a estrutura da tabela\n",
    "titanic_dummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checar primeiras 3 linhas\n",
    "titanic_dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Salvando a base tratada\n",
    "\n",
    "# O pkl é um formato do Python, que vai manter todas as propriedades do objeto\n",
    "#titanic_dummies.to_pickle('titanic1.pkl')\n",
    "# Parquet é um formato popular, eficiente, compatível com outras plataformas\n",
    "titanic_dummies.to_parquet('titanic1.parquet', engine='pyarrow')  # ou 'fastparquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  Rodando a primeira árvore\n",
    "\n",
    "# No Scikitlearn, vamos usar a seguinte estrutura:\n",
    "    \n",
    "# Um objeto X com as variáveis explicativas (miúsculo por serem várias)\n",
    "X = titanic_dummies.drop(columns = ['survived'])\n",
    "# Um objeto y com a variável resposta (target) minúsculo por ser só 1\n",
    "y = titanic_dummies['survived']\n",
    "\n",
    "# Estanciar a classe da árvore de decisão em um objeto chamado arvore\n",
    "# Este objeto não possui os dados em um primeiro momento\n",
    "# Mas ela possui todos os atributos e métodos que precisaremos\n",
    "arvore = DecisionTreeClassifier(criterion='gini', max_depth = 3, random_state=42)\n",
    "\n",
    "# Treinar o modelo com o método .fit(). Aqui processamos os dados!\n",
    "arvore.fit(X, y)\n",
    "\n",
    "# OBS: O objeto árvore contémodos os atributos e métodos que precisamos\n",
    "# Vamos usar esse objeto para várias coisas como:\n",
    "#    visualizar as regras da árvore, avaliar a árvore, classificar novas linhas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  Plotar a árvore\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(arvore, feature_names=X.columns.tolist(), class_names=['Not Survived', 'Survived'], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  Novos dados\n",
    "\n",
    "# Suponha que temos novos dados para classiicar\n",
    "novos_dados = X.tail() # como exemplo, vamos classificar as 5 últimas linhas\n",
    "print(novos_dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  Classificando com a árvore\n",
    "\n",
    "# Predict é o método que classifica as novas observações\n",
    "#    Lembrete: a classificação é pela classe mais frequente da folha\n",
    "classificação_novos_dados = arvore.predict(novos_dados)\n",
    "classificação_novos_dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  Avaliando a classificação\n",
    "# Vamos comparar a classificação da árvore com o valor observado\n",
    "\n",
    "# Guardar a classificação da árvore \n",
    "classificação_treino = arvore.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar com os valores reais por uma tabela cruzada\n",
    "print(pd.crosstab(classificação_treino, y, margins=True))\n",
    "print(pd.crosstab(classificação_treino, y, normalize='index'))\n",
    "print(pd.crosstab(classificação_treino, y, normalize='columns'))\n",
    "\n",
    "acertos = classificação_treino == y\n",
    "pct_acertos = acertos.sum()/acertos.shape[0]\n",
    "print(f'Acurácia (taxa de acerto): {pct_acertos:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando acurácia e matriz de confusão\n",
    "\n",
    "# Vamos avaliar o modelo com algumas funções próprias do Scikit-Learn\n",
    "# A função confudion_matrix faz basicamente a comparação acima\n",
    "cm = confusion_matrix(y, arvore.predict(X))\n",
    "# accuracy_score calcula o percentual de acertos\n",
    "ac = accuracy_score(y, arvore.predict(X))\n",
    "# Essa função pondera para forçar a distribuição da target como uniforme\n",
    "bac = balanced_accuracy_score(y, arvore.predict(X))\n",
    "\n",
    "print(f'\\nA acurácia da árvore é: {ac:.1%}')\n",
    "print(f'A acurácia balanceada da árvore é: {bac:.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização gráfica\n",
    "sns.heatmap(cm, \n",
    "            annot=True, fmt='d', cmap='viridis', \n",
    "            xticklabels=['Não Sobreviveu', 'Sobreviveu'], \n",
    "            yticklabels=['Não Sobreviveu', 'Sobreviveu'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatório de classificação do Scikit\n",
    "print('\\n', classification_report(y, arvore.predict(X)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
